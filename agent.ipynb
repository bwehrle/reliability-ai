{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b535428",
   "metadata": {},
   "source": [
    "\n",
    "# Reliability AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0073bc",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Remember to install dependendencies before using notebook:\n",
    "\n",
    "`pip install -qU langchain_community unstructured \"unstructured[md]\" nltk langchain-text-splitters langchain_chroma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f269297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your OPENAI_API_KEY\n",
      "Please enter your LANGSMITH_API_KEY\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set your API key\n",
    "def set_key(key):\n",
    "    if key not in os.environ:\n",
    "        print(f\"Please enter your {key}\")\n",
    "        os.environ[key] = getpass.getpass()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "set_key(\"OPENAI_API_KEY\")\n",
    "set_key(\"LANGSMITH_API_KEY\")\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "A simplified view of a component with a single reliability value (availability) and a list of dependencies.\n",
    "The availability of a component is the probability that the component is operational over the system's availability time period (normally 30d).\n",
    "'''\n",
    "from typing import List, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ServiceSLA(TypedDict):\n",
    "    metric_name: str\n",
    "    sla: float\n",
    "\n",
    "class Service(BaseModel):\n",
    "    \"\"\" A service is a component of a system.  It has a name, a list of dependencies, and a list of SLAs \"\"\"\n",
    "    name: str = Field(description=\"Name of the service\")\n",
    "    dependencies: dict[str, None] = Field(default_factory=dict[str], description=\"Dict of dependencies\")\n",
    "    SLAs: dict[str, ServiceSLA] = Field(default_factory=dict[str,ServiceSLA], description=\"Dict of SLAs\")\n",
    "\n",
    "    def calculate_availability_slo(self, lookup):\n",
    "        availability =  self.__get_availability()\n",
    "        for d in self.dependencies:\n",
    "            dep = lookup(d)\n",
    "            availability *= dep.calculate_availability_slo(lookup)\n",
    "    \n",
    "        return availability\n",
    "    \n",
    "    def __get_availability(self) -> float:\n",
    "        if 'availability' in self.SLAs:\n",
    "            return self.SLAs['availability']['sla']\n",
    "        else:\n",
    "            return float('nan')\n",
    "\n",
    "\n",
    "class System(BaseModel):\n",
    "    \"\"\" A system is a collection of services \"\"\"\n",
    "    services: dict[str, Service] = Field(default_factory=dict[str, Service], description=\"Dict of services\")\n",
    "\n",
    "    def calculate_availability_slo(self):\n",
    "        availability = 1.0\n",
    "        def lookup(name):\n",
    "            return self.services[name]\n",
    "        # TODO: use root node of services to calculate availability    \n",
    "        for svc in self.services.values():\n",
    "            availability *= svc.calculate_availability_slo(lookup)\n",
    "\n",
    "        return availability\n",
    "\n",
    "exmaple_system: dict[str, Service] = {\n",
    "    'Foo': Service(name='Foo', dependencies={'Bar': None}, slas={ 'availability': {'metric_name': 'availability', 'sla': 0.99}}),\n",
    "    'Bar': Service(name='Bar', dependencies={'Baz': None}, slas={ 'availability': {'metric_name': 'availability', 'sla': 0.99}}),\n",
    "    'Baz': Service(name='Baz', dependencies={}, slas={ 'availability': {'metric_name': 'availability', 'sla': 0.99}}),\n",
    "}\n",
    "\n",
    "# TODO: move into a module and turn into a test\n",
    "system = System(services=exmaple_system)\n",
    "sla = system.calculate_availability_slo()\n",
    "assert sla != float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "217a7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader, TextLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, ExperimentalMarkdownSyntaxTextSplitter\n",
    "from os import path\n",
    "\n",
    "notebook_name = \"reliable-agent\"\n",
    "file_path = path.abspath(\"\") + \"/\" + notebook_name + \"/docs/system-design-document.md\"\n",
    "loader = TextLoader(file_path)\n",
    "# sync loading data file\n",
    "data = loader.load()\n",
    "# check document is not empty\n",
    "assert len(data) >= 1\n",
    "assert isinstance(data[0], Document)\n",
    "doc_content = data[0].page_content\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"####\", \"Header 4\"),\n",
    "]\n",
    "\n",
    "# TODO: consider using RecursiveCharacterTextSplitter?\n",
    "\n",
    "markdown_splitter = ExperimentalMarkdownSyntaxTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(doc_content)\n",
    "assert len(md_header_splits) > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import  PydanticOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=md_header_splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "\n",
    "# TODO: convert to a agentic-type chain to cover cases where there is insufficient data in the document\n",
    "# TODO: convert to Graph RAG to have a more structured representation of the data\n",
    "parser = PydanticOutputParser(pydantic_object=System)\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Format instructions: {format_instructions}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs,\n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "output = rag_chain.invoke(\"What are the services that make up the described system in the context?\")\n",
    "assert output == System(services={\n",
    "    'Service A': Service(name='Service A', dependencies={'Service B': None, 'Service C': None}, SLAs={}),\n",
    "    'Service B': Service(name='Service B', dependencies={}, SLAs={}),\n",
    "    'Service C': Service(name='Service C', dependencies={}, SLAs={})\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a42122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
